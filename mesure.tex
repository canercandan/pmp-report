\section{Mesure de performance}

Je profite de ce rapport pour parler d'un travail qui m'a été demandé en entreprise. Nous utilisons le framework EO\footnote{Evolving Object, \url{http://eodev.sf.net}} pour développer nos algorithmes évolutionnaires\footnote{Algorithme évolutionnaire : \url{http://fr.wikipedia.org/wiki/Algorithme_evolutionnaire}}. Le sujet consistait à implémenter, au framework EO, un parallèlisme à mémoire partagée en utilisant OpenMP.

\subsection{Préambule}

Avant de commencer il est important de préciser que les EA\footnote{Algorithmes évolutionnaires} travaillent sur une population d'individus aussi appelé échantillon. Un individu étant représenté par un point dans l'échantillon, la complexité d'un problème est définit par le nombre de dimensions pour chaque individu.\\

Le problème est représenté par la fonction objectif qui prend en paramètre un individu (un point dans l'échantillon) et évalue toutes ses dimensions pour en déduire la qualité\footnote{Fitness en anglais}. La qualité est le critère de comparaison d'un point dans son échantillon.

\subsection{Identifier les ressources les plus utilisées}

Un test de profiling a été executé afin d'identifier les ressources les plus utilisées dans le framework EO. Le test nous a permi d'identifier une fonction qui est utilisée par une grande majorité des opérateurs\footnote{Opérateurs de sélection et variation} EO. Il s'agit de la fonction ``apply''. Elle prend en paramètres une population d'individus et un opérateur. Cette fonction va itérer sur tous les individus de la population et appliquer l'opérateur. Il peut être intéressant d'optimiser cette fonction. Nous allons nous limiter à transformer le code sequentiel en parallèle.

\subsection{Pseudo-code de la fonction apply}

L'algorithme \ref{apply} prend en paramètre une population ainsi qu'un opérateur à appliquer à chaque individu.

\incmargin{1em}
\begin{algorithm}[here]
  \dontprintsemicolon
  \label{apply}
  \Donnees{$P \in K_n, F \in Operateur$}
  \Res{$B' \in K_n$}
  \Deb{
    \Pour{$i\leftarrow 0$ \KwA $n$}{
      $F(P(i))$
    }
  }
  \caption{La fonction apply}
\end{algorithm}
\decmargin{1em}

\subsection{La fonction en parallèle}

L'algorithme \ref{omp_apply} transforme la fonction ``apply'' en parallèle en utilisant le modèle PRAM CREW\footnote{Concurantial Read Exclusive Write} et $O(n)$ processeurs pour parcourir tous les individus de la population.

\incmargin{1em}
\begin{algorithm}[here]
  \dontprintsemicolon
  \label{omp_apply}
  \Donnees{$P \in K_n, F \in Operateur$}
  \Res{$B' \in K_n$}
  \Deb{
    \textit{parallèle}\;
    \Pour{$i\leftarrow 0$ \KwA $n$}{
      $F(P(i))$
    }
  }
  \caption{La fonction omp\_apply}
\end{algorithm}
\decmargin{1em}

\subsection{Speed-up}

Après avoir crée la fonction alternative employant le parallèlisme à mémoire partagée, appelé ``omp\_apply'', nous allons étudier une solution de mesure du speed-up\footnote{$S_p = \frac{T_1^*}{T_p}$ : \url{http ://en.wikipedia.org/wiki/Speedup}}.\\

L'équation, en figure \ref{fig:mesure_speedup}, présente une méthode de mesure du speed-up et est implémentée dans l'algorithme \ref{algo_speedup}.

\begin{figure}[here]
\centering
$$Mesure\ du\ Speedup = r \sum^{P,D}_{k=0,l=0} S_{p_{kl}}$$
\caption{Mesure du Speedup}
\label{fig:mesure_speedup}
\end{figure}

\incmargin{1em}
\begin{algorithm}[here]
  \dontprintsemicolon
  \label{algo_speedup}
  \Donnees{$p, P, popStep, d, D, dimStep, r \in N$}
  \Deb{
    \Pour{$k\leftarrow p$ \KwA $P$}{
      \Pour{$l\leftarrow d$ \KwA $D$}{
        \Pour{$m\leftarrow 0$ \KwA $r$}{
          $T_s\leftarrow 0$\;
          $T_p\leftarrow 0$\;
          \Deb{
            $t_1\leftarrow omp\_get\_wtime()$\;
            ... code sequentiel avec $k$ et $l$ exécuté $m$ fois ...\;
            apply( ... )\;
            $t_2\leftarrow omp\_get\_wtime()$\;
            $T_s\leftarrow t_2 - t_1$\;
          }
          \Deb{
            $t_1\leftarrow omp\_get\_wtime()$\;
            ... code parallèle avec $k$ et $l$ exécuté $m$ fois ...\;
            omp\_apply( ... )\;
            $t_2\leftarrow omp\_get\_wtime()$\;
            $T_p\leftarrow t_2 - t_1$\;
          }
          ... on conserve le speed-up $\frac{T_s}{T_p}$ pour $k$ et $l$ ...\;
        }
      }
    }
  }
  \caption{La fonction de mesure du speedup}
\end{algorithm}
\decmargin{1em}

Une description des paramètres est disponible dans la figure \ref{fig:description_parametres}.

\begin{figure}[here]
  \centering
  \begin{tabular}{ | l | p{7cm} |}
    \hline
    \textbf{Paramètres} & \textbf{Description}\\\hline
    $p$ & la taille minimum de la population\\\hline
    $popStep$ & le pas d'iteration de la population\\\hline
    $P$ & la taille maximum de la population\\\hline
    $d$ & la taille minimum de la dimension\\\hline
    $dimStep$ & le pas d'iteration de la dimension\\\hline
    $D$ & la taille maximum de la dimension\\\hline
    $r$ & le nombre d'exécution pour chaque combinaison de $p$ et $d$\\\hline
  \end{tabular}
  \caption{Description des paramètres utilisés}
  \label{fig:description_parametres}
\end{figure}

\subsection{Mesures}

En prenant en compte les paramètres décrits précédement, nous allons lancer les tests sur deux architectures matérielles différentes présenté en figure \ref{fig:architectures}.\\

\begin{figure}[here]
  \centering
  \begin{tabular}{ | l | l | l | l |}
    \hline
    \textbf{Processeur} & \textbf{Nombre de coeurs} & \textbf{Fréquence} & \textbf{Cache L1}\\\hline
    Intel Centrino vPro & 2 & 2.40GHz & 3072KB\\\hline
    Intel Core i7 & 8 (hyperthreading\footnote{Hyperthreading : \url{http://en.wikipedia.org/wiki/hyperthreading}}) & 2.67GHz & 8192KB\\\hline
  \end{tabular}
  \caption{Architectures matérielles}
  \label{fig:architectures}
\end{figure}

Pour visualiser l'évolution du speed-up, nous utilisons un outil de génération de graphiques\footnote{Utilisation de matplotlib en python pour générer des boites a moustache}, avec les données produits par les tests.

\subsubsection{Fonctions objectifs}

Il est important de simuler toutes les compléxités de problèmes que l'on peut être ammené à résoudre. Pour nos tests, le choix a été orienté vers deux fonctions objectifs de complexité différente présenté en figure \ref{fig:objectifs}.

\begin{figure}[here]
  \centering
  \begin{tabular}{ | l | c | l |}
    \hline
    \textbf{Fonction objectifs} & \textbf{Complexité en temps} & \textbf{Algorithme}\\\hline
    L'algorithme du Sphere & $O(1)$ & $Sphere = \sum_{k=0}^n individu_k$\\\hline
    Problème à temps variable quelquonque & $O(n)$ & usleep($U(0,1) * 10$)\\\hline
  \end{tabular}
  \caption{Fonctions objectifs}
  \label{fig:objectifs}
\end{figure}

\subsubsection{Benchmark}

Pour faciliter et automatiser les tests, une liste de mesures a été élaboré avec les paramètres décrits précédement et un script contenant l'ensemble des tests à executer a été crée. La liste des mesures est présentée en figure \ref{fig:liste_mesures}.

\begin{figure}[here]
  \centering
  \begin{tabular}{ | c | l | }
    \hline
    \textbf{Mesure} & \textbf{Description}\\\hline
    1 & mesure pour toutes les combinaisons de $P$ et $D$\\\hline
    2 & mesure pour $P \in [1, 101[$ avec $D = 1000$\\\hline
    3 & mesure pour $P \in [1, 1001[$ avec $popStep = 10$ et $D = 1000$\\\hline
    4 & mesure pour $D \in [1, 101[$ avec $P = 1000$\\\hline
    5 & mesure pour $D \in [1, 1001[$ avec $dimStep = 10$ et $P = 1000$\\\hline
  \end{tabular}
  \caption{Fonctions objectifs}
  \label{fig:liste_mesures}
\end{figure}

\subsubsection{Dynamicité}

Parmi les optimisations possibles en OpenMP, il existe deux types de planification, la planification statique, utilisé par défaut, divise le nombre de taches à traiter à tous les processus disponibles et la planification dynamique maintien une fil de taches traitée au fur et à mesure par les processus disponibles. Nous evaluons la dynamicité par le rapport entre une mesure de speedup en mode statique et une mesure de speedup en mode dynamique\footnote{Dynamicité : $D_p = \frac{S_p}{S_p^d}$}.

\subsubsection{Résultats en $O(1)$}

Le benchmark a été executé dans un premier temps pour le problème du Sphere qui se resoud en temps constant. Les résultats de chaque mesure sont numérotés d'après le tableau des mesures décrits précédement.

% \begin{figure}[here]
% \centering
% \subfloat[speedup]{\includegraphics[scale=0.4]{openmp_measures_2010_11_27_23_00_05_470948_for_2_cores_n1_no_vartime/1_speedup_p1_pS10_P101_\subfloat[efficacité]{\includegraphics[scale=0.4]{openmp_measures_2010_11_27_23_00_05_470948_for_2_cores_n1_no_vartime/1_efficienty_p1_pS10_P101_d1_dS10_D101_r100_s1.pdf}}
% \subfloat[dynamicité]{\includegraphics[scale=0.4]{openmp_measures_2010_11_27_23_00_05_470948_for_2_cores_n1_no_vartime/1_dynamicity_p1_pS10_P101_d1_dS10_D101_r100_s1.pdf}}
% \caption{Mesure 1 en $O(1)$}
% \end{figure}

% \begin{figure}[here]
% \centering
% \includegraphics[scale=0.70]{openmp_measures_2010_11_27_23_00_05_470948_for_2_cores_n1_no_vartime/1_efficiency_p1_pS10_P101_d1_dS10_D101_r100_s1.pdf}
% \caption{Mesure de performance sur 2 coeurs pour résoudre un problème en temps constant}
% \label{fig:measure_2_cores_constant_time}
% \end{figure}

% \begin{figure}[here]
% \centering
% \includegraphics[scale=0.70]{openmp_measures_2010_11_27_23_00_05_470948_for_2_cores_n1_no_vartime/1_dynamicity_p1_pS10_P101_d1_dS10_D101_r100_s1.pdf}
% \caption{Mesure de performance sur 2 coeurs pour résoudre un problème en temps constant}
% \label{fig:measure_2_cores_constant_time}
% \end{figure}
